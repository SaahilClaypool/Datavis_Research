@article{Micallef2012,
abstract = {People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.},
author = {Micallef, Luana and Dragicevic, Pierre and Fekete, Jean Daniel},
doi = {10.1109/TVCG.2012.199},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Bayesian reasoning,Euler diagrams,base rate fallacy,crowdsourcing,glyphs,probabilistic judgment},
mendeley-groups = {Vis},
title = {{Assessing the effect of visualizations on bayesian reasoning through crowdsourcing}},
year = {2012}
}
@article{Gigerenzer1995,
abstract = {G. Gigerenzer and U. Hoffrage (1995) claimed that Bayesian inference problems, which have been notoriously difficult for laypeople to solve using base rates, hit rates, and false-alarm rates, become computationally simpler when information is presented with frequencies based on natural sampling. They made an evolutionary argument for the improved performance. The authors of the present article show that performance can improve with either probabilities or frequencies, depending on the rareness of the events and the type of information presented. When events are rare, probabilities are more difficult to understand than frequencies (i.e., 5 out of 1,000 vs. .005.). Furthermore, when the information is presented as joint and marginal events, nested sets become more apparent. Frequencies based on natural sampling have these desirable properties. The authors agree with Gigerenzer and Hoffrage that frequencies can improve Bayesian reasoning, but they attribute that improvement to the use of mental models that involve elements of nested sets. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Gigerenzer, Gerd and Hoffrage, Ulrich},
doi = {10.1037/0033-295X.102.4.684},
isbn = {0033-295X$\backslash$r1939-1471},
issn = {0033-295X},
journal = {Psychological Review},
mendeley-groups = {Vis},
pmid = {587},
title = {{How to improve Bayesian reasoning without instruction: Frequency formats.}},
year = {1995}
}
@article{Ottley2016,
abstract = {Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6{\%} to 62{\%}. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77{\%}. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100{\%}. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields},
author = {Ottley, Alvitta and Peck, Evan M. and Harrison, Lane T. and Afergan, Daniel and Ziemkiewicz, Caroline and Taylor, Holly A. and Han, Paul K.J. and Chang, Remco},
doi = {10.1109/TVCG.2015.2467758},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Accuracy,Bayes methods,Breast cancer,Cognition,Diseases,Sociology,Visualization},
mendeley-groups = {Vis},
pmid = {26390491},
title = {{Improving Bayesian Reasoning: The Effects of Phrasing, Visualization, and Spatial Ability}},
year = {2016}
}
@inproceedings{Tsai2011,
abstract = {Proper Bayesian reasoning is critical across a broad swath of domains that require practitioners to make predictions about the probability of events contingent upon earlier actions or events. However, much research on judgment has shown that people who are unfamiliar with Bayes' Theorem often reason quite poorly with conditional probabilities due to various cognitive biases. As such, this dissertation chronicles the development and evaluation of an interactive visualization designed to aid Bayes-naive people in solving conditional probability problems, in part by leveraging its graphical properties to head off the occurrence of biases. In three experiments, the visualization was tested with different classes of Bayesian problems. Experiment 1 showed that participants using the interactive visualization substantially improved their reasoning performance above that of previous debiasing methods for common, academic elementary Bayesian problems. Experiment 2 suggests that some measure of this improvement is retained for more complicated chains of reasoning Bayesian problems, with the majority of benefit going to those participants who self-assess themselves to be better in math ability than their peers. Experiment 3 showed that in real-time prediction/updating with a concrete, to-be-resolved Bayesian problem tied to a sporting event, participants using the visualization achieved better reasoning performance, seemed to suffer less from detrimental effects of overconfidence, and had internal reasoning accuracy that was solidly predictive of their accuracy with respect to matching the external event/world-a desirable property that allows for estimations of judges' outcome performance, based on readily available process information. Altogether, findings from three experiments point to visualizations being a rich area to mine, and prime candidate for expanding the toolbox of techniques that can be used to more accurately elicit the predictions of judges whose expertise lies beyond the realm of statistics. (PsycINFO Database Record (c) 2014 APA, all rights reserved)},
author = {Tsai, Jennifer and Miller, Sarah and Kirlik, Alex},
booktitle = {Proceedings of the Human Factors and Ergonomics Society},
doi = {10.1177/1071181311551079},
isbn = {9780945289395},
issn = {10711813},
mendeley-groups = {Vis},
title = {{Interactive visualizations to improve Bayesian reasoning}},
year = {2011}
}
@article{Brase2009,
abstract = {When web survey respondents self-administer a questionnaire, what they are doing is in many ways similar to what goes on in human–human interviews. The studies presented here demonstrate that enabling web survey respondents to engage in the equivalent of clarification dialogue can improve respondents' comprehension of questions and thus the accuracy of their answers, much as it can in human–human interviews. In two laboratory experiments, web survey respondents (1) answered more accurately when they could obtain clarification, that is, ground their understanding of survey questions, than when no clarification was available, and (2) answered particularly accurately with mixed-initiative clarification, where respondents could initiate clarification or the system could provide unsolicited clarification when respondents took too long to answer. Diagnosing the need for clarification based on respondent characteristics—in particular, age—proved more effective than relying on a generic model of all respondents' need for clarification. Although clarification dialogue increased response times, respondents preferred being able to request clarification than not. The current results suggest that bringing features of human dialogue to web surveys can exploit the advantages of both interviewer- and self-administration of questionnaires. Copyright {\#} 2007 John Wiley {\&} Sons, Ltd.},
author = {Brase, Gary L.},
doi = {10.1002/acp.1460},
isbn = {1099-0720},
issn = {08884080},
journal = {Applied Cognitive Psychology},
mendeley-groups = {Vis},
title = {{Pictorial representations in statistical reasoning}},
year = {2009}
}
@article{Chen1997,
abstract = {Research Guides. Database List A - Z. Welcome.},
author = {Chen, Chaomei and Czerwinski, Mary},
doi = {10.1080/13614569708914684},
issn = {17407842},
journal = {New Review of Hypermedia and Multimedia},
mendeley-groups = {Vis},
title = {{Spatial ability and visual navigation: An empirical study}},
year = {1997}
}
@article{Friederichs2014,
abstract = {Background: Physicians and medical students may lack sufficient numeracy skills to make treatment decisions, interpret test results, and practice evidence-based medicine. We evaluated whether the use of a tree diagram without numerical values as an aid for numerical processing might improve students' test results when dealing with percentages. Methods: A prospective randomized study was carried out with 102 third-year students. Participants received 3 diagnostic test problems and were asked to determine positive predictive values. The information in these tests was expressed either in (1) natural frequencies, (2) conditional probabilities, or (3) conditional probabilities with a tree diagram without numbers. Results: Ninety-eight (96.1{\%}) complete data sets could be obtained. The group working with natural frequencies achieved significantly higher test results (n = 29, mean score: 1.1, P = 0.045) than the group working with conditional probabilities (n = 34, mean score: 0.56). The students who were given a tree diagram in addition to conditional probabilities (n = 35, mean score: 1.26) also achieved significantly better scores than the group with conditional probabilities alone (P = 0.008). The difference between the group who had received natural frequencies and the group working with conditional probabilities and the tree diagram was not significant. Conclusions: We suggest the use of a tree diagram as a visual aid when dealing with diagnostic tests expressed in conditional probabilities. (PsycINFO Database Record (c) 2014 APA, all rights reserved) (journal abstract)},
author = {Friederichs, Hendrik and Ligges, Sandra and Weissenstein, Anne},
doi = {10.1177/0272989X13504499},
isbn = {0272-989X},
issn = {0272989X},
journal = {Medical Decision Making},
keywords = {conditional probabilities,medical education,numeracy,tree diagram},
mendeley-groups = {Vis},
pmid = {24085290},
title = {{Using tree diagrams without numerical values in addition to relative numbers improves students' numeracy skills: A randomized study in medical education}},
year = {2014}
}
A. B. Miller, C. J. Baines, P. Sun, T. To, and S. A. Narod. Twenty ﬁve year follow-up for breast cancer incidence and mortality of the canadian nationalbreastscreeningstudy: randomisedscreeningtrial. BMJ:British Medical Journal, 2014
@article{Welch2010,
author = {Welch, H. Gilbert and Black, William C.},
title = {Overdiagnosis in Cancer},
journal = {JNCI: Journal of the National Cancer Institute},
volume = {102},
number = {9},
pages = {605-613},
year = {2010},
doi = {10.1093/jnci/djq099},
URL = {http://dx.doi.org/10.1093/jnci/djq099},
eprint = {/oup/backfile/content_public/journal/jnci/102/9/10.1093_jnci_djq099/3/djq099.pdf}
}

@article{Cole1989,
 author = {Cole, W. G.},
 title = {Understanding Bayesian Reasoning via Graphical Displays},
 journal = {SIGCHI Bull.},
 volume = {20},
 number = {SI},
 month = mar,
 year = {1989},
 issn = {0736-6906},
 pages = {381--386},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/67450.67522},
 doi = {10.1145/67450.67522},
 acmid = {67522},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@incollection{Eddy1982,
abstract = {CONTENTS Part I. Introduction: 1. Judgment under uncertainty: Heuristics and biases Amos Tversky and Daniel Kahneman Part II. Representativeness: 2. Belief in the law of small numbers Amos Tversky and Daniel Kahneman 3. Subjective probability: A judgment of representativeness Daniel Kahneman and Amos Tversky 4. On the psychology of prediction Daniel Kahneman and Amos Tversky 5. Studies of representativeness Maya Bar-Hillel 6. Judgments of and by representativeness Amos Tversky and Daniel Kahneman Part III. Causality and Attribution: 7. Popular induction: Information is not necessarily informative Richard E. Nisbett, Eugene Borgida, Rick Crandall and Harvey Reed 8. Causal schemas in judgments under uncertainty Amos Tversky and Daniel Kahneman 9. Shortcomings in the attribution process: On the origins and maintenance of erroneous social assessments Lee Ross and Craig A. Anderson 10. Evidential impact of base rates Amos Tversky and Daniel Kahneman Part IV. Availability: 11. Availability: A heuristic for judging frequency and probability Amos Tversky and Daniel Kahneman 12. Egocentric biases in availability and attribution Michael Ross and Fiore Sicoly 13. The availability bias in social perception and interaction Shelley E. Taylor 14. The simulation heuristic Daniel Kahneman and Amos Tversky Part V. Covariation and Control: 15. Informal covariation asssessment: data-based versus theory-based judgments Dennis L. Jennings, Teresa M. Amabile and Lee Ross 16. The illusion of control Ellen J. Langer 17. Test results are what you think they are Loren J. Chapman and Jean Chapman 18. Probabilistic reasoning in clinical medicine: problems and opportunities David M. Eddy 19. Learning from experience and suboptimal rules in decision making Hillel J. Einhorn Part VI. Overconfidence: 20. Overconfidence in case-study judgments Stuart Oskamp 21. A progress report on the training of probability assessors Marc Alpert and Howard Raiffa 22. Calibration of probabilities: the state of the art to 1980 Sarah Lichtenstein, Baruch Fischhoff and Lawrence D. Phillips 23. For those condemned to study the past: heuristics and biases in hindsight Baruch Fischhoff Part VII. Multistage Evaluation: 24. Evaluation of compound probabilities in sequential choice John Cohen, E. I. Chesnick and D. Haran 25. Conservatism in human information processing Ward Edwards 26. The best-guess hypothesis in multistage inference Charles F. Gettys, Clinton Kelly III and Cameron R. Peterson 27. Inferences of personal characteristics on the basis of information retrieved from ones memory Yaacov Trope Part VIII. Corrective Procedures: 28. The robust beauty of improper linear models in decision making Robyn M. Dawes 29. The vitality of mythical numbers Max Singer 30. Intuitive prediction: biases and corrective procedures Daniel Kahneman and Amos Tversky 31. Debiasing Baruch Fischhoff 32. Improving inductive inference Richard E. Nesbett, David H. Krantz, Christopher Jepson and Geoffrey T. Fong Part IX. Risk Perception: 33. Facts versus fears: understanding perceived risk Paul Slovic, Baruch Fischhoff and Sarah Lichtenstein Part X. Postscript: 34. On the study of statistical intuitions Daniel Kahneman and Amos Tversky 35. Variants of uncertainty Daniel Kahneman and Amos Tversky},
author = {Eddy, D. M.},
booktitle = {Judgment under uncertainty: Heuristics and biases},
isbn = {0521240646},
title = {{Probabilistic reasoning in clinical medicine: Problems and opportunities}},
year = {1982}
}
@article{Galesic2009,
abstract = {OBJECTIVE: Icon arrays have been suggested as a potentially promising format for communicating risks to patients-especially those with low numeracy skills-but experimental studies are lacking. This study investigates whether icon arrays increase accuracy of understanding medical risks, and whether they affect perceived seriousness of risks and helpfulness of treatments.DESIGN: Two experiments were conducted on samples of older adults (n = 59, 62 to 77 years of age) and university students (n = 112, 26 to 35 years of age).MAIN OUTCOME MEASURES: Accuracy of understanding risk reduction; perceived seriousness of risks; perceived helpfulness of treatments.RESULTS: Icon arrays increased accuracy of both low- and high-numeracy people, even when transparent numerical representations were used. Risks presented via icon arrays were perceived as less serious than those presented numerically. With larger icon arrays (1,000 instead of 100 icons) risks were perceived more serious, and risk reduction larger.CONCLUSIONS: Icon arrays are a promising way of communicating medical risks to a wide range of patient groups, including older adults with lower numeracy skills},
author = {Galesic, Mirta and Garcia-Retamero, Rocio and Gigerenzer, Gerd},
doi = {10.1037/a0014474},
isbn = {0278-6133},
issn = {02786133},
journal = {Health Psychology},
keywords = {icon arrays,numeracy skills,older population,risk communication},
pmid = {19290713},
title = {{Using Icon Arrays to Communicate Medical Risks: Overcoming Low Numeracy}},
year = {2009}
}
@article{Cohen2007,
abstract = {Thirty participants performed a novel spatial inference task, which required them to imagine and draw the cross section of a three-dimensional (3-D) object. While performing the task, participants could interactively control two computer visualisations (animations) of the object. There were large individual differences in how frequently participants used the computer visualisations, which were related to spatial ability. Use of the interactive visualisations was highly predictive of performance on the cross-section task and mediated the correlation between spatial ability and performance. These findings suggest that interactive computer visualisations can aid performance on spatial inference tasks, but that they do so only for a subset of individuals who can discover how to best use the additional information that they provide. Copyright {\#} 2007 John Wiley {\&} Sons, Ltd.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {COHEN, CHERYL A. and HEGARTY, MARY},
doi = {10.1002/acp},
eprint = {NIHMS150003},
isbn = {1099-0720},
issn = {0888-4080},
journal = {Applied Cognitive Psychology},
pmid = {73986922},
title = {{Individual Differences in Use of External Visualisations to Perform an Internal Visualisation Task}},
year = {2007}
}
@article{Brown2014,
abstract = {Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user{\&}{\#}x2019;s interactions with a system reflect a large amount of the user{\&}{\#}x2019;s reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user{\&}{\#}x2019;s task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users{\&}{\#}x2019; interaction data. We achieve, depending on algorithm and encoding, between 62{\%} and 83{\%} accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user{\&}{\#}x2019;s personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95{\%} of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixedinitiative visual analytics systems.},
author = {Brown, Eli T. and Ottley, Alvitta and Zhao, Helen and Lin, Quan and Souvenir, Richard and Endert, Alex and Chang, Remco},
doi = {10.1109/TVCG.2014.2346575},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Analytic Provenance,Applied Machine Learning,User Interactions,Visualization},
title = {{Finding waldo: Learning about users from their interactions}},
year = {2014}
}

@article{Saket2018,
abstract = {User interfaces for data visualization often consist of two main components: control panels for user interaction and visual representation. A recent trend in visualization is directly embedding user interaction into the visual representations. For example, instead of using control panels to adjust visualization parameters, users can directly adjust basic graphical encodings (e.g., changing distances between points in a scatterplot) to perform similar parameterizations. However, enabling embedded interactions for data visualization requires a strong understanding of how user interactions influence the ability to accurately control and perceive graphical encodings. In this paper, we study the effectiveness of these graphical encodings when serving as the method for interaction. Our user study includes 12 interactive graphical encodings.We discuss the results in terms of task performance and interaction effectiveness metrics.},
author = {Saket, Bahador and Srinivasan, Arjun and Ragan, Eric D. and Endert, Alex},
doi = {10.1109/TVCG.2017.2680452},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information visualization,graphical encodings,graphical perception,user interaction},
title = {{Evaluating Interactive Graphical Encodings for Data Visualization}},
year = {2018}
}
